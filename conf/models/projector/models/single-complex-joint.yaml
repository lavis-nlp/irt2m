# for available projector models see irt2m.models.PROJECTORS
model: single context complex joint
model_kwargs:
  embedding_dim: 500
  loss: binary cross entropy
  regularizer: LPRegularizer
  regularizer_kwargs:
    p: 2.0
    weight: 0.1
    normalize: true

# for available datasets see irt2m.data.PROJECTOR_DATASETS
#   and their respective __init__ methods for *ds_kwargs
#
# contexts_per_sample is the amount of text contexts
# subbatch_size is batch_size if None
module:
  train_ds: vertex triple ringbuffer
  train_ds_kwargs:
    seed: 5012022
    contexts_per_sample: 1  # per batch
    max_contexts_per_sample: 10
  train_loader_kwargs:
    shuffle: true
    batch_size: 4

  valid_ds: mention flat
  valid_ds_kwargs:
    seed: 5012022
    contexts_per_sample: 1
    max_contexts_per_sample: 10
  valid_loader_kwargs:
    shuffle: false
    batch_size: 20

# for available optimizers see irt2m.models.OPTIMIZERS
optimizer: adam
optimizer_kwargs:
  lr: 5.0e-5
  weight_decay: 0.1

early_stopping: true
early_stopping_kwargs:
  min_delta: 0.001
  patience: 15
  mode: max
  monitor: irt2/inductive/all micro hits@10
