# for available projector models see irt2m.models.PROJECTORS
model: single context complex joint
model_kwargs:
  embedding_dim: 500
  loss: cross entropy
  regularizer: LPRegularizer
  regularizer_kwargs:
    p: 2.0
    weight: 0.1
    normalize: true


# which kgc evaluations to run while training
evaluations:
  - kgc/inductive     # open world kgc with projections (irt2.open_kgc_val*)
  - irt2/inductive    # official irt2 evaluation


# for available datasets see irt2m.data.PROJECTOR_DATASETS
#   and their respective __init__ methods for *ds_kwargs
#
# contexts_per_sample is the amount of text contexts
# subbatch_size is batch_size if None
module:
  train_ds: vertex entity ringbuffer
  train_ds_kwargs:
    seed: 5012022
    contexts_per_sample: 1  # per batch
    max_contexts_per_sample: 1
  train_loader_kwargs:
    shuffle: true
    batch_size: 8

  valid_ds: mention flat
  valid_ds_kwargs:
    seed: 5012022
    contexts_per_sample: 1
    max_contexts_per_sample: 1
  valid_loader_kwargs:
    shuffle: false
    batch_size: 60

# for available optimizers see irt2m.models.OPTIMIZERS
optimizer: adam
optimizer_kwargs:
  lr: 5.0e-5
  weight_decay: 0.1

early_stopping: true
early_stopping_kwargs:
  min_delta: 0.001
  patience: 5
  mode: max
  monitor: irt2/inductive/all micro hits@10
